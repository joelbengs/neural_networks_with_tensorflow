Here, I've practised using the ML library TensorFlow, as well as Pandas and Numpy to build neural networks.

- Exercise I - Training of simple Multi-Layer Perceptron models
- Exercise II - Model selection with Multi-Layer Perceptrons
- Exercise III - Convolutional and Recurrent Neural Networks

This was part of the course "Introduction to Artificial Neural Networks and Deep Learning" given at the Department of Astronomy and Theoretical Physics at Lund University.

_Course contents:_
The course covers the most common models in artificial neural networks with a focus on the multi-layer perceptron. The course also provides an introduction to deep learning. Selected topics:
- Feed-forward neural networks: the simple perceptron and the multi-layer perceptron, choice of suitable error functions and techniques to minimize them, how to detect and avoid overtraining, ensembles of neural networks and techniques to create them, Bayesian training of multi-layer perceptrons
- Recurrent neural networks: simple recurrent networks and their use in time series analysis, fully recurrent for both time series analysis and associative memories (Hopfield model), the simulated annealing optimization technique
- Self-organizing neural networks: networks that can extract principal components, networks for data clustering, learning vector quantization (LVQ), self-organizing feature maps (SOFM)
- Deep learning: Overview of deep learning, convolutional neural networks for classification of images, different techniques to avoid overtraining in deep networks, and techniques to pre-train deep networks.
